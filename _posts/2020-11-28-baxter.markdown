---
title: Recycle Baxter Sorter
subtitle: ROS|CV|Motion Control
subtext: Baxter robot recognizes bottles and cans and categorizes them into different bins
layout: default
modal-id: 3
date: 2020-11-28
img: Baxter_sorting.gif
thumbnail: Baxter_sorting.gif
alt: image-alt
video: https://www.youtube.com/embed/YJmehmPcRiY
project-date: December 2020
Baxter: Source Code
category: Web Development
intro: Brief Description
description: This is the final team project for the class ME495:Embeded System In Robotics at Northwestern University. In this project, we programmed a Rethink Baxter robot to sort bottles and cans located in front of it, and drop them into separate recycle bins. We used computer vision to detect and locate a couple of randomly placed bottles and cans, and used MoveIt to control the robot.
sub: Team Members
description2: Jake Ketchum<br>Kailey Smith<br>Yael Ben Shalom<br>Mingqing Yuan<br>Chris Aretakis
sub2: System Architecture
description3: Computer Vision(Yael and Jake):We use the realsense depth camera to capture image and use openCV to detect and classify the objects in the image.After the classification process,the programs saves the location and classification information which will be used in manipulation part.<br>Manipulation(Kailey, Mingqing and Chris):We use MoveIt! to control the motion of Baxter. After getting the location and classification information from CV, we call a customized service to return those information as list so Baxter can follow the planned trajectory.
sub3: General Procedures of motion
description4: 1. Move to the home position where the robot is safely above all objects.<br>2. For the current item in the list, display either the can image or the bottle image, depending on the classification.<br>3. Next, move to the object's (x,y) corrdinate at a safe z height away. This is the same height for bottles and cans.<br>4. Then move down to the appropriate perch height, depending on classification. (For example, the robot arm will be position further away from the table for bottle, since those are taller than cans).<br>5. Once safely at the perch height, move down so that the object is in between the grippers.<br> 6.Grasp the object.<br> 7.Move back up to the "safe" position as step 3.<br>8. Move back to the home position. This step was added to ensure predictable behavior of the robot arm.<br>9. Depending on the object's classification, move to the appropriate bin. Also, display the recylcing image.<br>10. Once over the bin, open the grippers and drop the object. Show that the object has been recycled with the bin image.<br>11. Repeat for all objects found.<br>For more detailed infomation, please visit my github page.
sub4: Result
description5: A good calibration of camera ensures we can get a precise location of bottles and cans relative to the	robot. After getting the locations, robot can move to each one of them and pick the objects. One deficit is we hard-coded the z distance from the gripper to cans/bottles. Even though it works well after many testings, it would be better to calculate the distance from the robot gripper camera.
sub6: Team Contributions
description7: Jake Ketchum:Aligned the Realsense Camera to Baxter frame and wrote code for classifying object.<br>Kailey Smith:Integrated the camera and manipulation node. Modified code and did test at Lab.<br>Yael Ben Shalom:Calculated an approximate offset for the realsense camera and wrote code for classfiying objects and rosunit test.<br>Mingqing Yuan:Laid out the preliminary code for the manipulation of the baxter and did initial movement testing.<br>Chris Aretakis:Laid out pseudo code for motion and designed a gripper for Baxter.

---
